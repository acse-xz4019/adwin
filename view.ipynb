{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_dataset = pd.read_csv('./archive/continuous dataset.csv')\n",
    "\n",
    "df1 = continuous_dataset.copy()\n",
    "df1[\"datecolumn\"] = pd.to_datetime(df1[\"datetime\"])\n",
    "df1 = df1.sort_values(by='datecolumn', ascending=True)\n",
    "\n",
    "# Extract components from the datetime\n",
    "df1['hour'] = df1['datecolumn'].dt.hour\n",
    "df1['day_of_week'] = df1['datecolumn'].dt.dayofweek\n",
    "df1['day'] = df1['datecolumn'].dt.day\n",
    "df1['month'] = df1['datecolumn'].dt.month\n",
    "df1['year'] = df1['datecolumn'].dt.year\n",
    "\n",
    "# Apply cyclical encoding\n",
    "df1['hour_sin'] = np.sin(2 * np.pi * df1['hour'] / 24)\n",
    "df1['hour_cos'] = np.cos(2 * np.pi * df1['hour'] / 24)\n",
    "df1['day_of_week_sin'] = np.sin(2 * np.pi * df1['day_of_week'] / 7)\n",
    "df1['day_of_week_cos'] = np.cos(2 * np.pi * df1['day_of_week'] / 7)\n",
    "max_day = 31  # Maximum number of days in a month\n",
    "df1['day_sin'] = np.sin(2 * np.pi * df1['day'] / max_day)\n",
    "df1['day_cos'] = np.cos(2 * np.pi * df1['day'] / max_day)\n",
    "df1['month_sin'] = np.sin(2 * np.pi * df1['month'] / 12)\n",
    "df1['month_cos'] = np.cos(2 * np.pi * df1['month'] / 12)\n",
    "\n",
    "df1.drop(['datetime', 'datecolumn', 'hour', 'day_of_week', 'day', 'month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nat_demand</th>\n",
       "      <th>T2M_toc</th>\n",
       "      <th>QV2M_toc</th>\n",
       "      <th>TQL_toc</th>\n",
       "      <th>W2M_toc</th>\n",
       "      <th>T2M_san</th>\n",
       "      <th>QV2M_san</th>\n",
       "      <th>TQL_san</th>\n",
       "      <th>W2M_san</th>\n",
       "      <th>T2M_dav</th>\n",
       "      <th>...</th>\n",
       "      <th>school</th>\n",
       "      <th>year</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970.3450</td>\n",
       "      <td>25.865259</td>\n",
       "      <td>0.018576</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>21.850546</td>\n",
       "      <td>23.482446</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>10.328949</td>\n",
       "      <td>22.662134</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>912.1755</td>\n",
       "      <td>25.899255</td>\n",
       "      <td>0.018653</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>22.166944</td>\n",
       "      <td>23.399255</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>10.681517</td>\n",
       "      <td>22.578943</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900.2688</td>\n",
       "      <td>25.937280</td>\n",
       "      <td>0.018768</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>22.454911</td>\n",
       "      <td>23.343530</td>\n",
       "      <td>0.017211</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>10.874924</td>\n",
       "      <td>22.531030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>889.9538</td>\n",
       "      <td>25.957544</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>22.110481</td>\n",
       "      <td>23.238794</td>\n",
       "      <td>0.017128</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>10.518620</td>\n",
       "      <td>22.512231</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>893.6865</td>\n",
       "      <td>25.973840</td>\n",
       "      <td>0.018981</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>21.186089</td>\n",
       "      <td>23.075403</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>9.733589</td>\n",
       "      <td>22.481653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nat_demand    T2M_toc  QV2M_toc   TQL_toc    W2M_toc    T2M_san  QV2M_san  \\\n",
       "0    970.3450  25.865259  0.018576  0.016174  21.850546  23.482446  0.017272   \n",
       "1    912.1755  25.899255  0.018653  0.016418  22.166944  23.399255  0.017265   \n",
       "2    900.2688  25.937280  0.018768  0.015480  22.454911  23.343530  0.017211   \n",
       "3    889.9538  25.957544  0.018890  0.016273  22.110481  23.238794  0.017128   \n",
       "4    893.6865  25.973840  0.018981  0.017281  21.186089  23.075403  0.017059   \n",
       "\n",
       "    TQL_san    W2M_san    T2M_dav  ...  school  year  hour_sin  hour_cos  \\\n",
       "0  0.001855  10.328949  22.662134  ...       0  2015  0.258819  0.965926   \n",
       "1  0.001327  10.681517  22.578943  ...       0  2015  0.500000  0.866025   \n",
       "2  0.001428  10.874924  22.531030  ...       0  2015  0.707107  0.707107   \n",
       "3  0.002599  10.518620  22.512231  ...       0  2015  0.866025  0.500000   \n",
       "4  0.001729   9.733589  22.481653  ...       0  2015  0.965926  0.258819   \n",
       "\n",
       "   day_of_week_sin  day_of_week_cos   day_sin   day_cos  month_sin  month_cos  \n",
       "0        -0.974928        -0.222521  0.571268  0.820763        0.5   0.866025  \n",
       "1        -0.974928        -0.222521  0.571268  0.820763        0.5   0.866025  \n",
       "2        -0.974928        -0.222521  0.571268  0.820763        0.5   0.866025  \n",
       "3        -0.974928        -0.222521  0.571268  0.820763        0.5   0.866025  \n",
       "4        -0.974928        -0.222521  0.571268  0.820763        0.5   0.866025  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nat_demand</th>\n",
       "      <th>T2M_toc</th>\n",
       "      <th>QV2M_toc</th>\n",
       "      <th>TQL_toc</th>\n",
       "      <th>W2M_toc</th>\n",
       "      <th>T2M_san</th>\n",
       "      <th>QV2M_san</th>\n",
       "      <th>TQL_san</th>\n",
       "      <th>W2M_san</th>\n",
       "      <th>T2M_dav</th>\n",
       "      <th>...</th>\n",
       "      <th>school</th>\n",
       "      <th>year</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>4.804800e+04</td>\n",
       "      <td>4.804800e+04</td>\n",
       "      <td>4.804800e+04</td>\n",
       "      <td>4.804800e+04</td>\n",
       "      <td>4.804800e+04</td>\n",
       "      <td>48048.000000</td>\n",
       "      <td>4.804800e+04</td>\n",
       "      <td>4.804800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1182.868647</td>\n",
       "      <td>27.399111</td>\n",
       "      <td>0.018313</td>\n",
       "      <td>0.079979</td>\n",
       "      <td>13.391049</td>\n",
       "      <td>26.921023</td>\n",
       "      <td>0.017844</td>\n",
       "      <td>0.106265</td>\n",
       "      <td>7.046675</td>\n",
       "      <td>24.719513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727793</td>\n",
       "      <td>2017.268336</td>\n",
       "      <td>-1.850372e-17</td>\n",
       "      <td>-5.649087e-17</td>\n",
       "      <td>-2.129499e-17</td>\n",
       "      <td>-1.900282e-17</td>\n",
       "      <td>2.011625e-03</td>\n",
       "      <td>-0.021411</td>\n",
       "      <td>5.150858e-02</td>\n",
       "      <td>-1.605391e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>192.068896</td>\n",
       "      <td>1.675462</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.065589</td>\n",
       "      <td>7.295502</td>\n",
       "      <td>3.018129</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.086293</td>\n",
       "      <td>4.103711</td>\n",
       "      <td>2.414019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>1.596256</td>\n",
       "      <td>7.071141e-01</td>\n",
       "      <td>7.071141e-01</td>\n",
       "      <td>7.071141e-01</td>\n",
       "      <td>7.071141e-01</td>\n",
       "      <td>7.141052e-01</td>\n",
       "      <td>0.699723</td>\n",
       "      <td>7.047891e-01</td>\n",
       "      <td>7.073770e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>85.192500</td>\n",
       "      <td>22.953455</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>19.765222</td>\n",
       "      <td>0.010247</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.060394</td>\n",
       "      <td>19.933740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-9.749279e-01</td>\n",
       "      <td>-9.009689e-01</td>\n",
       "      <td>-9.987165e-01</td>\n",
       "      <td>-0.994869</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1020.056900</td>\n",
       "      <td>26.160455</td>\n",
       "      <td>0.017236</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>7.544958</td>\n",
       "      <td>24.769281</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.036819</td>\n",
       "      <td>3.955051</td>\n",
       "      <td>22.954652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-7.818315e-01</td>\n",
       "      <td>-9.009689e-01</td>\n",
       "      <td>-7.247928e-01</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1168.427700</td>\n",
       "      <td>27.118051</td>\n",
       "      <td>0.018590</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>12.182103</td>\n",
       "      <td>26.167352</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.085968</td>\n",
       "      <td>5.992762</td>\n",
       "      <td>24.001718</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-6.123234e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.225209e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>-0.050649</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1327.563950</td>\n",
       "      <td>28.558344</td>\n",
       "      <td>0.019521</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>18.661282</td>\n",
       "      <td>28.712335</td>\n",
       "      <td>0.019242</td>\n",
       "      <td>0.157288</td>\n",
       "      <td>9.409871</td>\n",
       "      <td>26.243402</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>6.234898e-01</td>\n",
       "      <td>7.247928e-01</td>\n",
       "      <td>0.688967</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1754.882000</td>\n",
       "      <td>35.039575</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.521240</td>\n",
       "      <td>39.229726</td>\n",
       "      <td>39.063440</td>\n",
       "      <td>0.022165</td>\n",
       "      <td>0.484985</td>\n",
       "      <td>24.483937</td>\n",
       "      <td>34.216211</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.749279e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.987165e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         nat_demand       T2M_toc      QV2M_toc       TQL_toc       W2M_toc  \\\n",
       "count  48048.000000  48048.000000  48048.000000  48048.000000  48048.000000   \n",
       "mean    1182.868647     27.399111      0.018313      0.079979     13.391049   \n",
       "std      192.068896      1.675462      0.001607      0.065589      7.295502   \n",
       "min       85.192500     22.953455      0.012054      0.000000      0.008979   \n",
       "25%     1020.056900     26.160455      0.017236      0.026451      7.544958   \n",
       "50%     1168.427700     27.118051      0.018590      0.065201     12.182103   \n",
       "75%     1327.563950     28.558344      0.019521      0.117310     18.661282   \n",
       "max     1754.882000     35.039575      0.022690      0.521240     39.229726   \n",
       "\n",
       "            T2M_san      QV2M_san       TQL_san       W2M_san       T2M_dav  \\\n",
       "count  48048.000000  48048.000000  48048.000000  48048.000000  48048.000000   \n",
       "mean      26.921023      0.017844      0.106265      7.046675     24.719513   \n",
       "std        3.018129      0.001889      0.086293      4.103711      2.414019   \n",
       "min       19.765222      0.010247      0.000009      0.060394     19.933740   \n",
       "25%       24.769281      0.016584      0.036819      3.955051     22.954652   \n",
       "50%       26.167352      0.018351      0.085968      5.992762     24.001718   \n",
       "75%       28.712335      0.019242      0.157288      9.409871     26.243402   \n",
       "max       39.063440      0.022165      0.484985     24.483937     34.216211   \n",
       "\n",
       "       ...        school          year      hour_sin      hour_cos  \\\n",
       "count  ...  48048.000000  48048.000000  4.804800e+04  4.804800e+04   \n",
       "mean   ...      0.727793   2017.268336 -1.850372e-17 -5.649087e-17   \n",
       "std    ...      0.445100      1.596256  7.071141e-01  7.071141e-01   \n",
       "min    ...      0.000000   2015.000000 -1.000000e+00 -1.000000e+00   \n",
       "25%    ...      0.000000   2016.000000 -7.071068e-01 -7.071068e-01   \n",
       "50%    ...      1.000000   2017.000000  6.123234e-17 -6.123234e-17   \n",
       "75%    ...      1.000000   2019.000000  7.071068e-01  7.071068e-01   \n",
       "max    ...      1.000000   2020.000000  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       day_of_week_sin  day_of_week_cos       day_sin       day_cos  \\\n",
       "count     4.804800e+04     4.804800e+04  4.804800e+04  48048.000000   \n",
       "mean     -2.129499e-17    -1.900282e-17  2.011625e-03     -0.021411   \n",
       "std       7.071141e-01     7.071141e-01  7.141052e-01      0.699723   \n",
       "min      -9.749279e-01    -9.009689e-01 -9.987165e-01     -0.994869   \n",
       "25%      -7.818315e-01    -9.009689e-01 -7.247928e-01     -0.758758   \n",
       "50%       0.000000e+00    -2.225209e-01 -2.449294e-16     -0.050649   \n",
       "75%       7.818315e-01     6.234898e-01  7.247928e-01      0.688967   \n",
       "max       9.749279e-01     1.000000e+00  9.987165e-01      1.000000   \n",
       "\n",
       "          month_sin     month_cos  \n",
       "count  4.804800e+04  4.804800e+04  \n",
       "mean   5.150858e-02 -1.605391e-02  \n",
       "std    7.047891e-01  7.073770e-01  \n",
       "min   -1.000000e+00 -1.000000e+00  \n",
       "25%   -5.000000e-01 -8.660254e-01  \n",
       "50%    1.224647e-16 -1.836970e-16  \n",
       "75%    8.660254e-01  5.000000e-01  \n",
       "max    1.000000e+00  1.000000e+00  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['T2M_san','T2M_dav','QV2M_san','QV2M_dav'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names\n",
    "features = df1.columns\n",
    "features = features.drop(['nat_demand', 'holiday', 'school',\n",
    "       'year', 'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos',\n",
    "       'day_sin', 'day_cos', 'month_sin', 'month_cos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(df1[features])\n",
    "df1[features] = scaler.transform(df1[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df1[df1['year'] == 2016]\n",
    "test_data = df1[df1['year'] == 2017].reset_index(drop=True)\n",
    "\n",
    "X_train = train_data.drop(columns=['nat_demand'])\n",
    "y_train = train_data['nat_demand']\n",
    "\n",
    "X_test = test_data.drop(columns=['nat_demand'])\n",
    "y_test = test_data['nat_demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(features, targets, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - n_steps):\n",
    "        X.append(features.iloc[i:(i + n_steps)].values)  # Ensure to use .iloc and .values to get the slice as a NumPy array\n",
    "        y.append(targets.iloc[i + n_steps])  # Access the corresponding target value\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_steps = 24\n",
    "x, y = create_sequences(X_train, y_train, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义创建随机序列的函数\n",
    "def create_random_sequences(x, y, n_samples, n_steps=24):\n",
    "    X, Y = [], []\n",
    "    max_index = len(x) - 1\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # 随机选择一个目标点的索引，但要确保有足够的前序数据点\n",
    "        target_index = np.random.randint(n_steps, max_index)\n",
    "        \n",
    "        # 提取目标值\n",
    "        target_value = y[target_index]\n",
    "        \n",
    "        # 提取前24小时的特征数据\n",
    "        feature_values = x[target_index-n_steps:target_index]\n",
    "        \n",
    "        # 检查是否有缺失值，如果有则跳过该样本\n",
    "        if np.isnan(feature_values.values).any():\n",
    "            continue\n",
    "        \n",
    "        X.append(feature_values)\n",
    "        Y.append(target_value)\n",
    "    \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# 设定提取样本数量\n",
    "n_samples = 30  # 你想要的样本数量\n",
    "\n",
    "# 创建特征和目标\n",
    "X_t, Y_t = create_random_sequences(X_test, y_test, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LASSOQRLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LASSOQRLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_t, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(Y_t, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "t_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "test_size = int(0.8 * len(t_dataset))\n",
    "val_size = len(t_dataset) - test_size\n",
    "test_dataset, val_dataset = random_split(t_dataset, [test_size, val_size])\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 初始化隐藏状态和细胞状态\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim,device=x.device).requires_grad_()\n",
    "        # 分离隐藏状态，以避免梯度爆炸\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        # 在评估模式下打印全连接层的输入\n",
    "        if not self.training:\n",
    "            print(\"Input to the fully connected layer (eval mode):\", out[:, -1, :])\n",
    "        out = self.fc(out[:, -1, :])  # 只取序列的最后一个输出\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 1349277.6397125912, Val Loss: 1427728.7083333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50:  35%|███▍      | 190/548 [00:02<00:04, 85.96batch/s, train_loss=1.22e+6]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(features)\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets)\n\u001b[0;32m---> 33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 应用梯度裁剪\u001b[39;00m\n\u001b[1;32m     36\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ese-msc/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ese-msc/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 设置设备\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# 初始化模型并移动到设备\n",
    "input_dim = X_tensor.shape[2]  # 特征数\n",
    "hidden_dim = 200  # 隐藏层维度\n",
    "layer_dim = 2  # LSTM层的数量\n",
    "output_dim = 1  # 输出维度\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim).to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# 训练模型并记录损失\n",
    "num_epochs = 50  # 根据需要调整\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "plt.ion()  # 打开交互模式\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "    for features, targets in progress_bar:\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # 应用梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        progress_bar.set_postfix({'train_loss': loss.item()})\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in test_loader:\n",
    "            features, targets = features.to(device), targets.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            total_val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(test_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, epoch + 2), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, epoch + 2), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train and Validation Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}')\n",
    "\n",
    "plt.ioff()  # 关闭交互模式\n",
    "plt.show()  # 确保最后一张图表显示\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "Input to the fully connected layer (eval mode): tensor([[-0.9924, -0.9885, -0.9909, -0.9856,  0.9892, -0.9917, -0.9888, -0.9927,\n",
      "         -0.9944,  0.9827, -0.9891,  0.9935,  0.9915, -0.9883, -0.9883, -0.9916,\n",
      "          0.9944,  0.9951, -0.9867, -0.9856,  0.9949,  0.9873,  0.9840, -0.9861,\n",
      "         -0.9939, -0.9918,  0.9890,  0.9933, -0.9955,  0.9927,  0.9928,  0.9882,\n",
      "          0.9909,  0.9925, -0.9938,  0.9968,  0.9948, -0.9928,  0.9895,  0.9885,\n",
      "          0.9910,  0.9952,  0.9926,  0.9956, -0.9892, -0.9931, -0.9918, -0.9944,\n",
      "          0.9946,  0.9929,  0.9874, -0.9918,  0.9820,  0.9917,  0.9946,  0.9930,\n",
      "         -0.9955,  0.9928,  0.9877,  0.9955,  0.9910, -0.9883,  0.9937,  0.9923,\n",
      "         -0.9914,  0.9875, -0.9946, -0.9924,  0.9958, -0.9867,  0.9837, -0.9862,\n",
      "         -0.9861,  0.9949, -0.9938, -0.9903, -0.9895, -0.9915, -0.9952, -0.9903,\n",
      "         -0.9885,  0.9922,  0.9937, -0.9911,  0.9908, -0.9928,  0.9901, -0.9955,\n",
      "          0.9959,  0.9964, -0.9912,  0.9900,  0.9948, -0.9924, -0.9972, -0.9912,\n",
      "         -0.9940,  0.9917, -0.9950, -0.9738, -0.9911, -0.9904,  0.9950, -0.9950,\n",
      "          0.9863, -0.9921, -0.9884, -0.9909,  0.9907, -0.9903, -0.9950,  0.9919,\n",
      "         -0.9879, -0.9932, -0.9898, -0.9901,  0.9911, -0.9877,  0.9906,  0.9911,\n",
      "         -0.9916,  0.9947,  0.9926,  0.9920,  0.9937,  0.9911,  0.9905,  0.9936,\n",
      "          0.9866, -0.9917,  0.9929, -0.9906,  0.9935, -0.9908, -0.9948,  0.9918,\n",
      "         -0.9821,  0.9930,  0.9966, -0.9955,  0.9924, -0.9891,  0.9923, -0.9964,\n",
      "         -0.9912,  0.9867, -0.9917,  0.9948,  0.9941,  0.9952,  0.9946,  0.9927,\n",
      "         -0.9939, -0.9845,  0.9934,  0.9904,  0.9877,  0.9968,  0.9942,  0.9852,\n",
      "         -0.9904, -0.9924,  0.9895, -0.9936,  0.8804, -0.9901, -0.9955,  0.9828,\n",
      "          0.9897, -0.9916,  0.9917,  0.9832, -0.9862, -0.9949,  0.9927, -0.9885,\n",
      "         -0.9870, -0.9903,  0.9916,  0.9772,  0.9962,  0.9901, -0.9947, -0.9834,\n",
      "          0.9925,  0.9914,  0.9884,  0.9919, -0.9945, -0.9905,  0.9890,  0.9898,\n",
      "         -0.9887,  0.9895, -0.9888, -0.9891,  0.9958, -0.9943,  0.9879, -0.9947]],\n",
      "       device='mps:0')\n",
      "RMSE on test data: 1194.472900390625\n",
      "Predicted: [12.722781], Actual: [1013.8453]\n",
      "Predicted: [12.72278], Actual: [1153.0743]\n",
      "Predicted: [12.722779], Actual: [1262.3986]\n",
      "Predicted: [12.722778], Actual: [1245.7142]\n",
      "Predicted: [12.722781], Actual: [1238.0004]\n",
      "Predicted: [12.72278], Actual: [959.4347]\n",
      "Predicted: [12.72278], Actual: [1550.606]\n",
      "Predicted: [12.72278], Actual: [1443.097]\n",
      "Predicted: [12.722778], Actual: [1508.1285]\n",
      "Predicted: [12.722777], Actual: [1305.059]\n",
      "Predicted: [12.722781], Actual: [1269.8889]\n",
      "Predicted: [12.722778], Actual: [1144.5511]\n",
      "Predicted: [12.72278], Actual: [1126.8368]\n",
      "Predicted: [12.722778], Actual: [1029.7924]\n",
      "Predicted: [12.722777], Actual: [1351.993]\n",
      "Predicted: [12.722782], Actual: [996.376]\n",
      "Predicted: [12.72278], Actual: [1066.7897]\n",
      "Predicted: [12.722783], Actual: [1224.5922]\n",
      "Predicted: [12.722778], Actual: [907.1546]\n",
      "Predicted: [12.722779], Actual: [1056.5112]\n",
      "Predicted: [12.722777], Actual: [1346.747]\n",
      "Predicted: [12.72278], Actual: [1301.9598]\n",
      "Predicted: [12.72278], Actual: [1081.436]\n",
      "Predicted: [12.722781], Actual: [1104.1833]\n"
     ]
    }
   ],
   "source": [
    "# 应用模型在测试集上\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, targets in test_loader:\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "        outputs = model(features)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        true_values.extend(targets.cpu().numpy())\n",
    "\n",
    "# 转换为numpy数组\n",
    "predictions = np.array(predictions)\n",
    "true_values = np.array(true_values)\n",
    "\n",
    "# 计算RMSE\n",
    "rmse = np.sqrt(mean_squared_error(true_values, predictions))\n",
    "print(f\"RMSE on test data: {rmse}\")\n",
    "\n",
    "# 打印预测值和真实值\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Predicted: {predictions[i]}, Actual: {true_values[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(data, window_size, step_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(data) - window_size, step_size):\n",
    "        X.append(data[i:(i + window_size - 1)])\n",
    "        Y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'objective' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Average Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[0;32m---> 36\u001b[0m result \u001b[38;5;241m=\u001b[39m gp_minimize(objective, param_space, n_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'objective' is not defined"
     ]
    }
   ],
   "source": [
    "# # 参数空间定义\n",
    "# param_space = [\n",
    "#     Real(0.001, 0.1, name='learning_rate'),\n",
    "#     Integer(10, 100, name='hidden_dim')\n",
    "# ]\n",
    "\n",
    "# @use_named_args(param_space)\n",
    "# def objective(learning_rate, hidden_dim):\n",
    "#     model = LASSOQRLSTM(input_dim=X.shape[2], hidden_dim=hidden_dim, output_dim=Y.shape[1])\n",
    "#     # 使用数据集和定义的训练函数\n",
    "#     return train_model(model, dataloader, learning_rate)\n",
    "\n",
    "# # 调用贝叶斯优化\n",
    "# result = gp_minimize(objective, param_space, n_calls=20)\n",
    "# print(\"Best parameters:\", result.x)\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, learning_rate, epochs=5):\n",
    "    criterion = nn.MSELoss()  # 假设是回归问题\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {total_loss / len(dataloader)}\")\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "result = gp_minimize(objective, param_space, n_calls=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LASSOQRLSTM(input_dim=X.shape[2], hidden_dim=result.x[1], output_dim=Y.shape[1])\n",
    "# 假设 train_model 已经足够好地定义了\n",
    "train_model(model, dataloader, result.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def predict_density(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(data).numpy()\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=0.5)\n",
    "    kde.fit(predictions)\n",
    "    return kde\n",
    "\n",
    "# 为了预测，转换数据为张量\n",
    "data_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "kde_estimator = predict_density(model, data_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ese-msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
